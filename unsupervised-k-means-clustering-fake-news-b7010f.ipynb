{"cells":[{"cell_type":"markdown","metadata":{"_cell_guid":"4b094f53-086c-48e2-a9c0-3045bcdc31c0","_uuid":"c04e9cc0-53a5-440b-bafc-e9ccbe7c9201","trusted":true},"source":["## Introduction\n","\n","The purpose of this notebook is running K-Means clustering to see if the algorithm can sucessfully cluster the news in to 'Real' & 'Fake' using just the words in the articles"]},{"cell_type":"markdown","metadata":{"_cell_guid":"15ab19fb-21bd-4879-9029-c6bf42153f33","_uuid":"5a3c972c-9f14-452c-9b90-bb66a0743b3c","trusted":true},"source":["## Imports"]},{"cell_type":"code","execution_count":1,"metadata":{"_cell_guid":"7f781b05-2fe1-4baa-a655-5924516b5d73","_uuid":"50c7c3e2-4ff0-4b17-936a-1595f3252047","trusted":true},"outputs":[{"ename":"ModuleNotFoundError","evalue":"No module named 'gensim'","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","Cell \u001b[1;32mIn[1], line 11\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mstring\u001b[39;00m \u001b[39m# python library\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mre\u001b[39;00m \u001b[39m# regex library\u001b[39;00m\n\u001b[1;32m---> 11\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mgensim\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mparsing\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpreprocessing\u001b[39;00m \u001b[39mimport\u001b[39;00m preprocess_string, strip_tags, strip_punctuation, strip_multiple_whitespaces, strip_numeric, remove_stopwords, strip_short \u001b[39m# Preprocesssing\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mgensim\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodels\u001b[39;00m \u001b[39mimport\u001b[39;00m Word2Vec \u001b[39m# Word2vec\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m \u001b[39mimport\u001b[39;00m cluster \u001b[39m# Kmeans clustering\u001b[39;00m\n","\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'gensim'"]}],"source":["import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","\n","import matplotlib.pyplot as plt #  plotting and data visualization\n","import seaborn as sns # improve visuals\n","sns.set() # Set as default style\n","\n","import string # python library\n","import re # regex library\n","\n","from gensim.parsing.preprocessing import preprocess_string, strip_tags, strip_punctuation, strip_multiple_whitespaces, strip_numeric, remove_stopwords, strip_short # Preprocesssing\n","from gensim.models import Word2Vec # Word2vec\n","\n","from sklearn import cluster # Kmeans clustering\n","from sklearn import metrics # Metrics for evaluation\n","from sklearn.decomposition import PCA #PCA\n","from sklearn.manifold import TSNE #TSNE"]},{"cell_type":"markdown","metadata":{"_cell_guid":"2e2e1270-fd87-4cbc-8406-7a0846d328fe","_uuid":"82bee1ed-9079-46a1-bacc-917a1bab3eff","trusted":true},"source":["## Data Analysis & Cleanup"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"3d652ec6-f050-4062-98ce-02e1f8058f65","_uuid":"d0b6867f-f001-4a7f-be97-71b6ae8f960b","trusted":true},"outputs":[],"source":["fake = pd.read_csv(\"Fake.csv\")\n","true = pd.read_csv(\"True.csv\")"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"88a4992d-bee0-4a53-b289-62acbd0c89c2","_uuid":"43d91724-c1bb-4d32-b38a-591941fd512f","trusted":true},"outputs":[],"source":["fake.head(10)"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"c40f3aff-df7b-496b-969b-5d8ed43e6df6","_uuid":"01d5eab4-469e-41da-ace6-8799f3b0702c","trusted":true},"outputs":[],"source":["true.head(10)"]},{"cell_type":"markdown","metadata":{},"source":["The first issue as seen above is that the True data contains:\n","\n","1. A reuters disclaimer that the article is a tweet\n","> \"The following statements were posted to the verified Twitter accounts of U.S. President Donald Trump, @realDonaldTrump and @POTUS.  The opinions expressed are his own. Reuters has not edited the statements or confirmed their accuracy.  @realDonaldTrump\"\n","\n","\n","2. City Name and then publisher at the start\n","> WASHINGTON (Reuters)\n","\n","so in the next block of code I remove this from the data"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# The following is a crude way to remove the @realDonaldTrump tweet disclaimer and State/Publisher at start of text\n","\n","cleansed_data = []\n","for data in true.text:\n","    if \"@realDonaldTrump : - \" in data:\n","        cleansed_data.append(data.split(\"@realDonaldTrump : - \")[1])\n","    elif \"(Reuters) -\" in data:\n","        cleansed_data.append(data.split(\"(Reuters) - \")[1])\n","    else:\n","        cleansed_data.append(data)\n","\n","true[\"text\"] = cleansed_data\n","true.head(10)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["true.text[7]"]},{"cell_type":"markdown","metadata":{},"source":["Some of the text still contains various characters/words such as:\n","\n","1. Links\n","2. Timestamps\n","3. Brackets\n","4. Numbers\n","\n","So we will be removing all such characters from the real and fake data using genlib preprocessing and a custom regex for the links in preperation for the Word2Vec\n","\n","Before that however, the title and text will be merged in to one so that it can all be preprocessed together. I will also add a label for real and fake which will be used later to evaluate our clustering"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Merging title and text\n","fake['Sentences'] = fake['title'] + ' ' + fake['text']\n","true['Sentences'] = true['title'] + ' ' + true['text']\n","\n","# Adding fake and true label\n","fake['Label'] = 0\n","true['Label'] = 1\n","\n","# We can merge both together since we now have labels\n","final_data = pd.concat([fake, true])\n","\n","# Randomize the rows so its all mixed up\n","final_data = final_data.sample(frac=1).reset_index(drop=True)\n","\n","# Drop columns not needed\n","final_data = final_data.drop(['title', 'text', 'subject', 'date'], axis = 1)\n","\n","final_data.head(10)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Here we preprocess the sentences\n","def remove_URL(s):\n","    regex = re.compile(r'https?://\\S+|www\\.\\S+|bit\\.ly\\S+')\n","    return regex.sub(r'',s)\n","\n","# Preprocessing functions to remove lowercase, links, whitespace, tags, numbers, punctuation, strip words\n","CUSTOM_FILTERS = [lambda x: x.lower(), strip_tags, remove_URL, strip_punctuation, strip_multiple_whitespaces, strip_numeric, remove_stopwords, strip_short]\n","\n","# Here we store the processed sentences and their label\n","processed_data = []\n","processed_labels = []\n","\n","for index, row in final_data.iterrows():\n","    words_broken_up = preprocess_string(row['Sentences'], CUSTOM_FILTERS)\n","    # This eliminates any fields that may be blank after preprocessing\n","    if len(words_broken_up) > 0:\n","        processed_data.append(words_broken_up)\n","        processed_labels.append(row['Label'])"]},{"cell_type":"markdown","metadata":{},"source":["## Word2Vec"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Word2Vec model trained on processed data\n","model = Word2Vec(processed_data, min_count=1)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["model.wv.most_similar(\"country\")"]},{"cell_type":"markdown","metadata":{},"source":["## Sentence Vectors"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"outputs":[],"source":["# Getting the vector of a sentence based on average of all the word vectors in the sentence\n","# We get the average as this accounts for different sentence lengths\n","\n","def ReturnVector(x):\n","    try:\n","        return model[x]\n","    except:\n","        return np.zeros(100)\n","    \n","def Sentence_Vector(sentence):\n","    word_vectors = list(map(lambda x: ReturnVector(x), sentence))\n","    return np.average(word_vectors, axis=0).tolist()\n","\n","X = []\n","for data_x in processed_data:\n","    X.append(Sentence_Vector(data_x))"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["X_np = np.array(X)\n","X_np.shape"]},{"cell_type":"markdown","metadata":{},"source":["## Clustering"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Training for 2 clusters (Fake and Real)\n","kmeans = cluster.KMeans(n_clusters=2, verbose=1)\n","\n","# Fit predict will return labels\n","clustered = kmeans.fit_predict(X_np)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["testing_df = {'Sentence': processed_data, 'Labels': processed_labels, 'Prediction': clustered}\n","testing_df = pd.DataFrame(data=testing_df)\n","\n","testing_df.head(10)"]},{"cell_type":"markdown","metadata":{},"source":["The results above show that its correctly clustered them in some cases where 0 is fake news and 1 is real news"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["correct = 0\n","incorrect = 0\n","for index, row in testing_df.iterrows():\n","    if row['Labels'] == row['Prediction']:\n","        correct += 1\n","    else:\n","        incorrect += 1\n","        \n","print(\"Correctly clustered news: \" + str((correct*100)/(correct+incorrect)) + \"%\")"]},{"cell_type":"markdown","metadata":{},"source":["## Visualization"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# PCA of sentence vectors\n","pca = PCA(n_components=2)\n","pca_result = pca.fit_transform(X_np)\n","\n","PCA_df = pd.DataFrame(pca_result)\n","PCA_df['cluster'] = clustered\n","PCA_df.columns = ['x1','x2','cluster']"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# T-SNE\n","tsne = TSNE(n_components=2)\n","tsne_result = tsne.fit_transform(pca_result)\n","\n","TSNE_df = pd.DataFrame(tsne_result)\n","TSNE_df['cluster'] = clustered\n","TSNE_df.columns = ['x1','x2','cluster']"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Plots\n","fig, ax = plt.subplots(1, 2, figsize=(12,6))\n","sns.scatterplot(data=PCA_df,x='x1',y='x2',hue='cluster',legend=\"full\",alpha=0.5,ax=ax[1])\n","sns.scatterplot(data=TSNE_df,x='x1',y='x2',hue='cluster',legend=\"full\",alpha=0.5,ax=ax[0])\n","ax[0].set_title('Visualized on TSNE')\n","ax[1].set_title('Visualized on PCA')"]},{"cell_type":"markdown","metadata":{},"source":["## Custom News Tests"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Testing with fake news generated from https://www.thefakenewsgenerator.com/\n","onion_data = \"Flint Residents Learn To Harness Superpowers, But Trump Gets Away Again They developed superpowers after years of drinking from a lead-poisoned water supply. But just having incredible abilities doesn't make them superheroes. Not yet. Donald Trump faced off against the superpowered civilians but he got away before they could catch him\"\n","\n","# Preprocess article\n","onion_data = preprocess_string(onion_data, CUSTOM_FILTERS)\n","\n","# Get sentence vector\n","onion_data = Sentence_Vector(onion_data)\n","\n","# Get prediction\n","kmeans.predict(np.array([onion_data]))"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# News from BBC\n","\n","bbc_data = \"Nasa Mars 2020 Mission's MiMi Aung on women in space Next year, Nasa will send a mission to Mars. The woman in charge of making the helicopter that will be sent there – which is set to become the first aircraft to fly on another planet – is MiMi Aung. At 16, MiMi travelled alone from Myanmar to the US for access to education. She is now one of the lead engineers at Nasa. We find out what it's like being a woman in space exploration, and why her mum is her biggest inspiration.\"\n","\n","# Preprocess article\n","bbc_data = preprocess_string(bbc_data, CUSTOM_FILTERS)\n","\n","# Get sentence vector\n","bbc_data = Sentence_Vector(bbc_data)\n","\n","# Get prediction\n","kmeans.predict(np.array([bbc_data]))"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.0"}},"nbformat":4,"nbformat_minor":4}
